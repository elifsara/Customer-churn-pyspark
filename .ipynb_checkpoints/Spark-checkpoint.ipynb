{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ecdec34",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction with PySpark\n",
    "\n",
    "This project uses PySpark to perform classification on a telecom dataset to predict customer churn. It demonstrates big data handling, feature engineering, and machine learning with Spark's MLlib."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bff2ba-677d-411f-a1a8-caa18fa9c4e9",
   "metadata": {},
   "source": [
    "### Importing Libraries\n",
    "\n",
    "We start by importing necessary Python and PySpark libraries for data handling and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2a4a797-6a63-4a76-96ff-f2e60bb0dba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c527c88b-9407-4dd5-af23-7bba573cd377",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "We load the customer churn dataset using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de4b0e0d-f6dc-48a5-826a-74a5f625cdce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Names</th>\n",
       "      <th>Age</th>\n",
       "      <th>Total_Purchase</th>\n",
       "      <th>Account_Manager</th>\n",
       "      <th>Years</th>\n",
       "      <th>Num_Sites</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Cameron Williams</td>\n",
       "      <td>42.0</td>\n",
       "      <td>11066.80</td>\n",
       "      <td>0</td>\n",
       "      <td>7.22</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Kevin Mueller</td>\n",
       "      <td>41.0</td>\n",
       "      <td>11916.22</td>\n",
       "      <td>0</td>\n",
       "      <td>6.50</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Eric Lozano</td>\n",
       "      <td>38.0</td>\n",
       "      <td>12884.75</td>\n",
       "      <td>0</td>\n",
       "      <td>6.67</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Phillip White</td>\n",
       "      <td>42.0</td>\n",
       "      <td>8010.76</td>\n",
       "      <td>0</td>\n",
       "      <td>6.71</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Cynthia Norton</td>\n",
       "      <td>37.0</td>\n",
       "      <td>9191.58</td>\n",
       "      <td>0</td>\n",
       "      <td>5.56</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             Names   Age  Total_Purchase  Account_Manager  Years  \\\n",
       "0           0  Cameron Williams  42.0        11066.80                0   7.22   \n",
       "1           1     Kevin Mueller  41.0        11916.22                0   6.50   \n",
       "2           2       Eric Lozano  38.0        12884.75                0   6.67   \n",
       "3           3     Phillip White  42.0         8010.76                0   6.71   \n",
       "4           4    Cynthia Norton  37.0         9191.58                0   5.56   \n",
       "\n",
       "   Num_Sites  Churn  \n",
       "0        8.0      1  \n",
       "1       11.0      1  \n",
       "2       12.0      1  \n",
       "3       10.0      1  \n",
       "4        9.0      1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset using pandas\n",
    "df = pd.read_csv(\"churn.csv\")\n",
    "\n",
    "# Preview the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a48ecff-b634-4291-8258-d66accb4e165",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "Before we build a machine learning model, we explore the dataset to:\n",
    "\n",
    "- Understand the structure of the data\n",
    "- Check for missing values\n",
    "- Examine statistical summaries\n",
    "- Review the distribution of the target variable (`Churn`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fca821bc-b71d-4283-a152-fb64c6711bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age</th>\n",
       "      <th>Total_Purchase</th>\n",
       "      <th>Account_Manager</th>\n",
       "      <th>Years</th>\n",
       "      <th>Num_Sites</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>900.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>449.500000</td>\n",
       "      <td>41.816667</td>\n",
       "      <td>10062.824033</td>\n",
       "      <td>0.481111</td>\n",
       "      <td>5.273156</td>\n",
       "      <td>8.587778</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>259.951919</td>\n",
       "      <td>6.127560</td>\n",
       "      <td>2408.644532</td>\n",
       "      <td>0.499921</td>\n",
       "      <td>1.274449</td>\n",
       "      <td>1.764836</td>\n",
       "      <td>0.372885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>224.750000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>8497.122500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.450000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>449.500000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>10045.870000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.215000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>674.250000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>11760.105000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.110000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>899.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>18026.010000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.150000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0         Age  Total_Purchase  Account_Manager       Years  \\\n",
       "count  900.000000  900.000000      900.000000       900.000000  900.000000   \n",
       "mean   449.500000   41.816667    10062.824033         0.481111    5.273156   \n",
       "std    259.951919    6.127560     2408.644532         0.499921    1.274449   \n",
       "min      0.000000   22.000000      100.000000         0.000000    1.000000   \n",
       "25%    224.750000   38.000000     8497.122500         0.000000    4.450000   \n",
       "50%    449.500000   42.000000    10045.870000         0.000000    5.215000   \n",
       "75%    674.250000   46.000000    11760.105000         1.000000    6.110000   \n",
       "max    899.000000   65.000000    18026.010000         1.000000    9.150000   \n",
       "\n",
       "        Num_Sites       Churn  \n",
       "count  900.000000  900.000000  \n",
       "mean     8.587778    0.166667  \n",
       "std      1.764836    0.372885  \n",
       "min      3.000000    0.000000  \n",
       "25%      7.000000    0.000000  \n",
       "50%      8.000000    0.000000  \n",
       "75%     10.000000    0.000000  \n",
       "max     14.000000    1.000000  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d6de6030-7ed2-42e4-8fb9-a3ff2a0d18e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0         0\n",
       "Names              0\n",
       "Age                0\n",
       "Total_Purchase     0\n",
       "Account_Manager    0\n",
       "Years              0\n",
       "Num_Sites          0\n",
       "Churn              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dca4dae3-c5a3-4a4f-886d-cfa3928d4b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn\n",
       "0    750\n",
       "1    150\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of target variable\n",
    "df[\"Churn\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6d48ec-6e73-4941-97b5-2884c23c9a7e",
   "metadata": {},
   "source": [
    "## Converting to Spark DataFrame\n",
    "\n",
    "After completing our exploratory data analysis with pandas, we convert the dataset into a Spark DataFrame.\n",
    "\n",
    "This allows us to take advantage of PySpark’s distributed machine learning pipeline tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6cfc6b05-e689-46c9-8742-c3ec84f637f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Unnamed: 0: long (nullable = true)\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: long (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Churn: long (nullable = true)\n",
      "\n",
      "+----------+----------------+----+--------------+---------------+-----+---------+-----+\n",
      "|Unnamed: 0|           Names| Age|Total_Purchase|Account_Manager|Years|Num_Sites|Churn|\n",
      "+----------+----------------+----+--------------+---------------+-----+---------+-----+\n",
      "|         0|Cameron Williams|42.0|       11066.8|              0| 7.22|      8.0|    1|\n",
      "|         1|   Kevin Mueller|41.0|      11916.22|              0|  6.5|     11.0|    1|\n",
      "|         2|     Eric Lozano|38.0|      12884.75|              0| 6.67|     12.0|    1|\n",
      "|         3|   Phillip White|42.0|       8010.76|              0| 6.71|     10.0|    1|\n",
      "|         4|  Cynthia Norton|37.0|       9191.58|              0| 5.56|      9.0|    1|\n",
      "+----------+----------------+----+--------------+---------------+-----+---------+-----+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Start a Spark session\n",
    "spark = SparkSession.builder.appName(\"ChurnPrediction\").getOrCreate()\n",
    "\n",
    "# Convert pandas DataFrame to Spark DataFrame\n",
    "spark_df = spark.createDataFrame(df)\n",
    "\n",
    "# Show structure and first few records\n",
    "spark_df.printSchema()\n",
    "spark_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b985487-7ca1-4bfd-a6fd-b5f4157c5759",
   "metadata": {},
   "source": [
    "## Preprocessing for Machine Learning\n",
    "\n",
    "Before training a model, we need to prepare the data by:\n",
    "\n",
    "- Renaming the target column to `label`\n",
    "- Selecting relevant numeric features\n",
    "- Assembling features into a single vector column (`features`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f57e796-fb53-4a98-b942-9b999a152fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[42.0,11066.8,0.0...|    1|\n",
      "|[41.0,11916.22,0....|    1|\n",
      "|[38.0,12884.75,0....|    1|\n",
      "|[42.0,8010.76,0.0...|    1|\n",
      "|[37.0,9191.58,0.0...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Rename the label column\n",
    "spark_df = spark_df.withColumnRenamed(\"Churn\", \"label\")\n",
    "\n",
    "# Define feature columns\n",
    "feature_cols = [\"Age\", \"Total_Purchase\", \"Account_Manager\", \"Years\", \"Num_Sites\"]\n",
    "\n",
    "# Assemble features into a single column\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "data = assembler.transform(spark_df).select(\"features\", \"label\")\n",
    "\n",
    "# Show a sample of the resulting DataFrame\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4246e36-006b-4b16-bc84-3e3681abee2b",
   "metadata": {},
   "source": [
    "## Splitting the Data\n",
    "\n",
    "We split the data into training and testing sets.\n",
    "\n",
    "- **Training Set (70%)**: Used to fit the machine learning model.\n",
    "- **Testing Set (30%)**: Used to evaluate how well the model performs on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f4db3fd8-fed8-48b3-a747-6bc6bdfb9ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Records: 633\n",
      "Testing Records: 267\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets (70/30)\n",
    "train_data, test_data = data.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "# Check the size of each set\n",
    "print(\"Training Records:\", train_data.count())\n",
    "print(\"Testing Records:\", test_data.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ba2a79-821e-4179-9616-04a77d705699",
   "metadata": {},
   "source": [
    "## Training a Logistic Regression Model\n",
    "\n",
    "We use PySpark’s `LogisticRegression` to build a simple binary classification model that predicts customer churn.\n",
    "\n",
    "The model learns to separate customers likely to churn (`label = 1`) from those likely to stay (`label = 0`) based on the selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "39eeaf1b-921f-462b-a3f7-39e47d9263d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/05 22:39:08 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Initialize logistic regression model\n",
    "lr = LogisticRegression(featuresCol='features', labelCol='label')\n",
    "\n",
    "# Fit the model to training data\n",
    "lr_model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f052d801-059b-41c9-80fd-0f6ce43a94be",
   "metadata": {},
   "source": [
    "## Making Predictions and Evaluating the Model\n",
    "\n",
    "After training the model, we evaluate its performance on the test set using:\n",
    "\n",
    "- **AUC (Area Under the ROC Curve)**: Measures how well the model distinguishes between the two classes.\n",
    "- **Prediction samples**: Review a few predictions to observe the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "52194577-a396-45d9-b77b-71c65ffe8026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------------------+\n",
      "|label|prediction|         probability|\n",
      "+-----+----------+--------------------+\n",
      "|    1|       0.0|[0.81979276108790...|\n",
      "|    1|       0.0|[0.64336714680380...|\n",
      "|    1|       1.0|[0.43756059264380...|\n",
      "|    1|       1.0|[0.38762905932159...|\n",
      "|    1|       0.0|[0.50779432812282...|\n",
      "+-----+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "AUC: 0.9405\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Predict on test data\n",
    "predictions = lr_model.transform(test_data)\n",
    "\n",
    "# Show example predictions\n",
    "predictions.select(\"label\", \"prediction\", \"probability\").show(5)\n",
    "\n",
    "# Evaluate using AUC\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\")\n",
    "auc = evaluator.evaluate(predictions)\n",
    "print(f\"AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0f8641-1fba-45e0-a98f-f7e8bfee3f00",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this project, we built a machine learning pipeline using PySpark to predict customer churn in a telecom dataset.\n",
    "\n",
    "- We started with exploratory data analysis using pandas.\n",
    "- Then we transformed the dataset into a Spark DataFrame for scalable processing.\n",
    "- A logistic regression model was trained using key customer features.\n",
    "- The model achieved an AUC of **0.9405**, indicating strong capability in distinguishing churners from non-churners.\n",
    "\n",
    "Although the results are promising, further improvements could be made by:\n",
    "\n",
    "- Testing different classification models (e.g., Random Forest, Gradient Boosted Trees)\n",
    "- Incorporating categorical variables with proper encoding\n",
    "- Applying hyperparameter tuning to optimize performance\n",
    "\n",
    "This notebook demonstrates how big data tools like PySpark can be effectively applied to solve real-world classification problems at scale."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
